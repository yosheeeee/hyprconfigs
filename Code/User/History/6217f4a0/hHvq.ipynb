{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dzxb5pk4i0iB"
      },
      "source": [
        "# Переход от задачи регрессии к задаче классификации\n",
        "\n",
        "**Задание:** Построить регрессионную модель спрогнозировать число сданных в аренду велосипедов (см. файл DataSet5_2.csv) с использованием множественной регресии.\n",
        "\n",
        "Ввести граничное значение (экономически выгодное значение числа сданных в аренду) для велосипедов и ввести дополнительную колонку (колонку класса) означающую эффективность или нет (1 или 0).\n",
        "\n",
        "Построить модель классификации для предсказания дней эффективной работы. Сравнить качество моделей предсказания дней эффективной работы (модели регрессии и классификации)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6Nue2niKi0iC"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Invalid file path or buffer object type: <class 'ellipsis'>",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# данные о работе пункта проката велосипедов\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m data\n",
            "File \u001b[0;32m/usr/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[0;32m/usr/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[0;32m/usr/lib/python3.12/site-packages/pandas/io/common.py:728\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    725\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[0;32m--> 728\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    737\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
            "File \u001b[0;32m/usr/lib/python3.12/site-packages/pandas/io/common.py:472\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(filepath_or_buffer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filepath_or_buffer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    470\u001b[0m ):\n\u001b[1;32m    471\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid file path or buffer object type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(filepath_or_buffer)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 472\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m IOArgs(\n\u001b[1;32m    475\u001b[0m     filepath_or_buffer\u001b[38;5;241m=\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    476\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    479\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    480\u001b[0m )\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid file path or buffer object type: <class 'ellipsis'>"
          ]
        }
      ],
      "source": [
        "# данные тут https://disk.yandex.ru/d/GqGh2GMLEkl2Aw\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# данные о работе пункта проката велосипедов\n",
        "data = pd.read_csv(...)\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cslx7wsxi0iD"
      },
      "source": [
        "Построим регрессионную модель на наших данных.\n",
        "\n",
        "ВАЖНО: в данном случае мы строим регресссионную модель для **описания** наших данных, а не для задачи прогноза. Поэтому мы НЕ делим данные на тренировочную и тестовую выборки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOYk5mpsi0iD"
      },
      "outputs": [],
      "source": [
        "X = data[['holiday', 'humidity', 'registered', 'summer', 'temp', 'windspeed', 'workingday']]\n",
        "y = data['count']\n",
        "\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X, y)\n",
        "\n",
        "y_pred = regressor.predict(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lIQsJgWi0iE"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(14, 12))\n",
        "\n",
        "plt.plot(y_pred, color='orange', label='Предсказание модели')\n",
        "plt.plot(y, color=\"blue\", label='Исходные данные')\n",
        "\n",
        "plt.grid()\n",
        "plt.xlabel(\"Номер измерения\")\n",
        "plt.ylabel(\"Количество\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tinE65-wi0iE"
      },
      "outputs": [],
      "source": [
        "# TODO: добавить метрики качества регрессии"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LClUg0-i0iF"
      },
      "source": [
        "От задачи регрессии перейдём к задаче классификации.\n",
        "\n",
        "Будем классифицировать по колонке \"count\", в которой содержится информация о количестве сданных в аренду велосипедов в текущий день. Выделим пороговое значение, по которому будем считать, были ли день удачным (мы сдали в аренду много велосипедов, класс \"1\") или неудачным (класс 0)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbIxixvli0iF"
      },
      "outputs": [],
      "source": [
        "# Создание целевой переменной для классификации\n",
        "# TODO: посчитайте пороговое значение для классификации, как медиану по значению \"count\"\n",
        "# разделите данные на 2 класс 0 и 1, относительно порога\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB10trQpi0iG"
      },
      "source": [
        "Для оценки качества предсказаний моделей мы сначала построим матрицу ошибок (confusion matrix).\n",
        "\n",
        "Матрица ошибок – это показатель успешности классификации, где классов два или более. Это таблица с 4 различными комбинациями сочетаний прогнозируемых и фактических значений.\n",
        "\n",
        "![image-2.png](attachment:image-2.png)\n",
        "\n",
        "\n",
        "Для понимания, воспользуемся \"беременной\" аналогией:\n",
        "\n",
        "![image-3.png](attachment:image-3.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLPay9izi0iH"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "conf_matrix = confusion_matrix(y_pred=y_pred_class, y_true=y_class)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbvKwtc2i0iH"
      },
      "source": [
        "Исходя из полученных значений посчитаем следующие метрики:\n",
        "\n",
        "- **Accuracy**\n",
        "\n",
        "Одной из наиболее простых, а поэтому и распространенной метрикой является accuracy (!доля правильных ответов)\n",
        "\n",
        "$Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$\n",
        "\n",
        "- **Precision**\n",
        "\n",
        "Точность, показывает количество истинно положительных исходов из всего набора положительных меток и считается по следующей формуле:\n",
        "\n",
        "$Precision = \\frac{TP}{TP + FP}$\n",
        "\n",
        "- **Recall**\n",
        "\n",
        "В русском языке для этого термина используется слово «полнота» или «чувствительность». Эта метрика определяет количество истинно положительных среди всех меток класса, которые были определены как «положительный» и вычисляется по следующей формуле:\n",
        "\n",
        "$Recall = \\frac{TP}{TP+FN}$\n",
        "\n",
        "- **F-мера** (англ. F-score)\n",
        "\n",
        "Precision и recall не зависят, в отличие от accuracy, от соотношения классов и потому применимы в условиях несбалансированных выборок.\n",
        "\n",
        "Понятно что чем выше точность и полнота, тем лучше. Но в реальной жизни максимальная точность и полнота не достижимы одновременно и приходится искать некий баланс. Поэтому, хотелось бы иметь некую метрику которая объединяла в себе информацию о точности и полноте нашего алгоритма. В этом случае нам будет проще принимать решение о том какую реализацию запускать в производство (у кого больше тот и круче). Именно такой метрикой является F-мера.\n",
        "\n",
        "F₁-мера — среднее гармоническое между precision и recall:\n",
        "\n",
        "$F_1 = (\\frac{precision^{-1}+recall^{-1}}{2})^{-1} = 2* \\frac{precision * recall}{precision + recall}$\n",
        "\n",
        "Среднее гармоническое взвешенное $F_β$ (F1-мера — частный случай $F_β$-меры для $β = 1$). $F_β$ измеряет эффективность классификатора учитывая recall в $β$ раз более важным чем precision:\n",
        "\n",
        "$F_β = (1+β^2) \\frac{precision * recall}{β^2 * precision + recall}$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uya0uK8Vi0iI"
      },
      "outputs": [],
      "source": [
        "# метрики можно посчитать по отдельности\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n",
        "\n",
        "#Рассчитать долю правильных ответов\n",
        "accuracy = accuracy_score(y_pred=y_pred_class, y_true=y_class)\n",
        "\n",
        "# Рассчитать точность (precision)\n",
        "precision = precision_score(y_pred=y_pred_class, y_true=y_class)\n",
        "\n",
        "# Рассчитать полноту (recall)\n",
        "recall = recall_score(y_pred=y_pred_class, y_true=y_class)\n",
        "\n",
        "# Рассчитать F-меру (F-measure)\n",
        "F_measure = f1_score(y_pred=y_pred_class, y_true=y_class)\n",
        "\n",
        "# Рассчитать Log loss\n",
        "Log_loss = log_loss(y_pred=y_pred_class, y_true=y_class)\n",
        "\n",
        "\n",
        "print(f'''Accuracy: {accuracy:.2f}\n",
        "Precision: {precision:.2f}\n",
        "Recall: {recall:.2f}\n",
        "F1: {F_measure:.2f}\n",
        "Log loss: {Log_loss:.2f}''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Fcm8b8hi0iI"
      },
      "source": [
        "#### ROC-кривая\n",
        "\n",
        "**ROC-кривая** (англ. receiver operating characteristic, рабочая характеристика приёмника) — график, позволяющий *оценить качество бинарной классификации*, отображает соотношение между долей объектов от общего количества носителей признака, верно классифицированных как несущие признак (англ. true positive rate, TPR, называемой чувствительностью алгоритма классификации), и долей объектов от общего количества объектов, не несущих признака, ошибочно классифицированных как несущие признак (англ. false positive rate, FPR, величина 1-FPR называется специфичностью алгоритма классификации) при варьировании порога решающего правила.\n",
        "\n",
        "Также известна как **кривая ошибок**. Анализ классификаций с применением ROC-кривых называется ROC-анализом.\n",
        "\n",
        "*Источник Википедия https://ru.wikipedia.org/wiki/ROC-%D0%BA%D1%80%D0%B8%D0%B2%D0%B0%D1%8F*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue_KB23di0iJ"
      },
      "source": [
        "Вариант, как понять ROC-кривую: она описывает взаимосвязь между чувствительностью модели (TPR, или true positives rate — доля истинно положительных примеров) и её специфичностью (описываемой в отношении долей ложноположительных результатов: 1-FPR).\n",
        "\n",
        "$ TPR = \\frac{TP}{P}$, где $P$ - это все положительные результаты, а $TP$ - истинно положительные результаты.\n",
        "\n",
        "$ FPR = \\frac{FP}{N}$, где $N$ - это все негативные результаты, а $FP$ - ложноположительные результаты.\n",
        "\n",
        "**Обобщая**: вы сравниваете, как чувствительность модели меняется по отношению к ложно положительным долям на разных порогах отсечения. Модель опирается на порог отсечения, чтобы принимать решения по входным данным и относить их к положительным.\n",
        "\n",
        "*Использованы материалы https://habr.com/ru/companies/netologyru/articles/582756/*\n",
        "\n",
        "**Площадь под кривой (AUC = Area Under Curve)** — это более сложная метрика точности, которая помогает понять, насколько детерминирована модель. Она описывает, насколько хорошо модель прогнозирует положительный класс, когда фактический результат является положительным.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFK1X9bGi0iJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Рассчитать ROC-кривую\n",
        "fpr, tpr, thresholds = roc_curve( y_pred_class, y_class)\n",
        "\n",
        "# Рассчитать площадь под ROC-кривой (AUC-ROC)\n",
        "roc_auc = roc_auc_score(y_pred_class, y_class)\n",
        "\n",
        "# Визуализировать ROC-кривую\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
        "# plt.plot(fpr, color='darkorange')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.title('ROC-кривая')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr5Z-qmbi0iJ"
      },
      "source": [
        "Сравним полученные результаты с работой классификатора. Используем KNN классификацию.\n",
        "\n",
        "Для дальнейшей работы добавим колонку \"class\" в наш датафрейм."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AnwV3sYi0iJ"
      },
      "outputs": [],
      "source": [
        "data['class'] = (y > threshold).astype(int)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XvKXqqpi0iK"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Разделяем данные на обучающий и тестовый наборы\n",
        "X = df[['holiday', 'humidity', 'summer', 'temp', 'windspeed', 'workingday']]\n",
        "y = df['class']\n",
        "\n",
        "\n",
        "# Создаем и обучаем модель k-Nearest Neighbors\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)  # Здесь 3 - это количество соседей, можно выбрать другое значение\n",
        "knn_model.fit(X, y)\n",
        "\n",
        "# Предсказание классов для данных\n",
        "clss2 = knn_model.predict(X)\n",
        "\n",
        "# Предсказание вероятностей классов для данных\n",
        "clss3 = knn_model.predict_proba(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkA0vSA7i0iK"
      },
      "outputs": [],
      "source": [
        "# TODO: построить confusion matrix для полученных результатов\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JA5_p7mai0iK"
      },
      "outputs": [],
      "source": [
        "# для упрощения кода, можно воспользоваться функцией classification_report,\n",
        "# которая сразу посчитает нам все необходимые метрики\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y, clss2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4gYMACDi0iK"
      },
      "source": [
        "Как интерпретировать classification_report:\n",
        "\n",
        "Мы получаем сводку precision, recall и f1-меру для каждого класса.\n",
        "\n",
        "Support в данном контексте - это количество элементов каждого класса в тестовой выборке.\n",
        "\n",
        "Также мы видим accuracy (долю правильных ответов) и общий объём тестовой выбоки.\n",
        "\n",
        "Также мы видим macro average (среднее арифметическое без учета веса для каждой метки), weighted average (среднее арифметическое с учетом веса для каждой метки)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VLl6waMi0iL"
      },
      "outputs": [],
      "source": [
        "# Рассчитать ROC-кривую\n",
        "fpr, tpr, thresholds = roc_curve(y, clss2)\n",
        "\n",
        "# Рассчитать площадь под ROC-кривой (AUC-ROC)\n",
        "roc_auc = roc_auc_score(y, clss2)\n",
        "\n",
        "# Визуализировать ROC-кривую\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
        "# plt.plot(fpr, color='darkorange')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.title('ROC-кривая')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "MNE_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
